{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw_7_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание\n",
        "\n",
        "1. Попробуйте обучить нейронную сеть GRU/LSTM для предсказания сентимента сообщений с твитера на примере https://www.kaggle.com/datasets/arkhoshghalb/twitter-sentiment-analysis-hatred-speech\n",
        "\n",
        "2. Опишите, какой результат вы получили? Что помогло вам улучшить ее точность?"
      ],
      "metadata": {
        "id": "EtFjCOEa0aOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подключаемся к google disc"
      ],
      "metadata": {
        "id": "t_wykl-oxIXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erceRVNobgwI",
        "outputId": "d21ff61a-8756-451c-e8e2-fb9d8ebec020"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Распаковываем архив"
      ],
      "metadata": {
        "id": "Guj63zIMxPfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip '/content/drive/MyDrive/Twitter Sentiment Analysis.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCbzY_6xjN2V",
        "outputId": "796653d2-605e-42bd-aa04-b61d7d70c035"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Twitter Sentiment Analysis.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Смотрим на данные"
      ],
      "metadata": {
        "id": "W5VAfiEHxUAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "F8nehxQwjN4u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[df_train['label']==0].head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FjWF8RaOj_ch",
        "outputId": "f5923e2b-b207-41f7-f115-89774a8079d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bee041b2-0d31-467f-b328-acef78ef7fe7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bee041b2-0d31-467f-b328-acef78ef7fe7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bee041b2-0d31-467f-b328-acef78ef7fe7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bee041b2-0d31-467f-b328-acef78ef7fe7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[df_train['label']==1].head(7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "tuRk66J0k2Uq",
        "outputId": "47b25c37-e915-473c-caca-3ca588d76ecd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id  label                                              tweet\n",
              "13  14      1  @user #cnn calls #michigan middle school 'buil...\n",
              "14  15      1  no comment!  in #australia   #opkillingbay #se...\n",
              "17  18      1                             retweet if you agree! \n",
              "23  24      1    @user @user lumpy says i am a . prove it lumpy.\n",
              "34  35      1  it's unbelievable that in the 21st century we'...\n",
              "56  57      1            @user lets fight against  #love #peace \n",
              "68  69      1  ð©the white establishment can't have blk fol..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38a04303-c620-4fcb-a860-31293312abec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>retweet if you agree!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>@user @user lumpy says i am a . prove it lumpy.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>it's unbelievable that in the 21st century we'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>@user lets fight against  #love #peace</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>69</td>\n",
              "      <td>1</td>\n",
              "      <td>ð©the white establishment can't have blk fol...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38a04303-c620-4fcb-a860-31293312abec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-38a04303-c620-4fcb-a860-31293312abec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-38a04303-c620-4fcb-a860-31293312abec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0 - positive<br>\n",
        "1 - negative"
      ],
      "metadata": {
        "id": "tfE2CFASkpsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCS2PcBmj_fG",
        "outputId": "035411cc-0214-4a3a-81f7-12ce49b01aa9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    29720\n",
              "1     2242\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fYVIkXy8lRmI",
        "outputId": "e6ea9258-3dc1-4b43-ef5f-bddb65027fcb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                              tweet\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
              "1  31964   @user #white #supremacists want everyone to s...\n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
              "3  31966  is the hp and the cursed child book up for res...\n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6d43a65-fcbf-4eb8-ae58-c76a79ada2d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6d43a65-fcbf-4eb8-ae58-c76a79ada2d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6d43a65-fcbf-4eb8-ae58-c76a79ada2d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6d43a65-fcbf-4eb8-ae58-c76a79ada2d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Предобработка"
      ],
      "metadata": {
        "id": "DA7kf0LSli_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stop-words pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v38-dGWLlehd",
        "outputId": "075a28c5-3f17-4701-ddd7-66b482baee7c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stop-words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 29.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32911 sha256=87b0db533ee6f17185e854ed4e9fda3250319ca4abdae325d89796746da168b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n",
            "Successfully built stop-words\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, stop-words, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 stop-words-2018.7.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import re"
      ],
      "metadata": {
        "id": "6AI7Mc5pleoV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраняем в переменные стоп-слова и знаки пунктуации"
      ],
      "metadata": {
        "id": "FYC6kHd2xbtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sw = set(get_stop_words(\"en\"))\n",
        "#sw"
      ],
      "metadata": {
        "id": "rW3lvme6leq7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "puncts = set(punctuation)"
      ],
      "metadata": {
        "id": "S6BaX1MCles4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем функцию по очистке твитов от стоп-слов, знаков пунктуации приводим всё в нижний регистр"
      ],
      "metadata": {
        "id": "y2n5neRPxkbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "morpher = MorphAnalyzer()\n",
        "\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in puncts)\n",
        "    txt = txt.lower()\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
        "    return \" \".join(txt)"
      ],
      "metadata": {
        "id": "iIq2-UPEleyE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train['tweet'].iloc[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53rfgpVGm8VU",
        "outputId": "94396a35-62bb-4072-d1a3-6225bd7a6644"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     @user when a father is dysfunctional and is s...\n",
            "Name: tweet, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['tweet'].iloc[:1].apply(preprocess_text).values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7DfDvSUmsxV",
        "outputId": "976e074b-3895-4a25-ca27-1467ed922bf2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['user father dysfunctional selfish drags kids dysfunction run'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разбиваем обучающую выборку на трейн и валидацию"
      ],
      "metadata": {
        "id": "bIbeLwHbx6U7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def train_valid_split(Xt):\n",
        "    df_train, df_val = train_test_split(Xt, test_size=0.15, random_state=13)\n",
        "    return df_train, df_val"
      ],
      "metadata": {
        "id": "ilJkx0Enni5c"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_valid_split(df_train)"
      ],
      "metadata": {
        "id": "g6LoxsrUoJcg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFW86U6Boa_Z",
        "outputId": "f76e9990-48de-4c18-af56-dfe151546457"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    25250\n",
              "1     1917\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_val['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyHLeShEofoX",
        "outputId": "f751575f-e180-4daa-de03-3451b7f6d33f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4470\n",
              "1     325\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Структура лейблов в тренировочной и валидационной выборке примерно одинакова"
      ],
      "metadata": {
        "id": "QebheNBcoqA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Делаем препроцессинг текстов в трейне и валидации"
      ],
      "metadata": {
        "id": "rM4sCMvIyFn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm \n",
        "tqdm.pandas()\n",
        "\n",
        "df_train['tweet'] = df_train['tweet'].progress_apply(preprocess_text)\n",
        "df_val['tweet'] = df_val['tweet'].progress_apply(preprocess_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Acu2WbXLnZOZ",
        "outputId": "8a3da147-272c-43d4-bb1e-ea8cbed7528b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27167/27167 [00:06<00:00, 3999.62it/s]\n",
            "100%|██████████| 4795/4795 [00:01<00:00, 3956.40it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем корпус слов, на котором будем обучаться"
      ],
      "metadata": {
        "id": "XTH5mw0ryKwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus = \" \".join(df_train[\"tweet\"])\n",
        "train_corpus = train_corpus.lower()\n",
        "#train_corpus"
      ],
      "metadata": {
        "id": "tpv3_weLnZQn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разбиваем весь корпус на токены"
      ],
      "metadata": {
        "id": "S3bg6DGoyQaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "tokens = word_tokenize(train_corpus)\n",
        "tokens[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEFPMDYCnZS5",
        "outputId": "3c958b62-484d-4d06-ef64-40bb8e695af8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['thankful', 'sense', 'touch', 'thankful', 'positive']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отфильтруем данные\n",
        "\n",
        "и соберём в корпус N наиболее частых токенов"
      ],
      "metadata": {
        "id": "1o9aR-0ApLPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_filtered = [word for word in tokens if word.isalnum()]"
      ],
      "metadata": {
        "id": "g6-mFJl8nZVG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "max_words = 2500\n",
        "dist = FreqDist(tokens_filtered)\n",
        "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]  # вычитание 1 для padding\n",
        "len(tokens_filtered_top)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5aPNnXRpQxu",
        "outputId": "b33a3a90-0d80-4ca2-9186-f1e5d884ed92"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2499"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_filtered_top[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XswRyYoxpQz8",
        "outputId": "2cde0981-5689-4e53-ec50-222e2691e8c0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['user', 'love', 'day', 'happy', 'amp', 'just', 'will', 'im', 'u', 'time']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Соберем словарь из самых популярных токенов, где каждому токену будет присвоен уникальный индекс"
      ],
      "metadata": {
        "id": "gkauejhNycko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}\n",
        "#vocabulary"
      ],
      "metadata": {
        "id": "EK-TqN6jpQ1-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим функцию по созданию из твитов последовательностей заданной длины"
      ],
      "metadata": {
        "id": "T5U3NAodymOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "max_len = 20\n",
        "\n",
        "def text_to_sequence(text, maxlen):\n",
        "    result = []\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "    for word in tokens_filtered:\n",
        "        if word in vocabulary:\n",
        "            result.append(vocabulary[word])\n",
        "\n",
        "    padding = [0] * (maxlen-len(result))\n",
        "    return result[-maxlen:] + padding"
      ],
      "metadata": {
        "id": "JS-yyK3jpfXc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Переведем трейн и валидационную выборку в набор последовательностей"
      ],
      "metadata": {
        "id": "jCJ2RmjbyxnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"tweet\"]])\n",
        "x_val = np.asarray([text_to_sequence(text, max_len) for text in df_val[\"tweet\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZtb9pBgpfaN",
        "outputId": "0db3b9f7-a2bb-454c-f3b1-c0247a06e444"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.86 s, sys: 14.3 ms, total: 3.87 s\n",
            "Wall time: 3.87 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['tweet'].iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-SwFCH1tpfcP",
        "outputId": "92f64fb5-6944-4316-b4ea-d1d8af294952"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thankful sense touch thankful positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59A8GFWJpfe8",
        "outputId": "078e90fd-e8a8-450a-af12-327fd48c8a42"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  16,  895, 1406,   16,   18,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем архитектуру нейронной сети LSTM"
      ],
      "metadata": {
        "id": "sP4h5ErHy85b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class LSTMFixedLen(nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, use_last=True):\n",
        "        super().__init__()\n",
        "        self.use_last = use_last\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, ht = self.lstm(x)\n",
        "       \n",
        "        if self.use_last:\n",
        "            last_tensor = lstm_out[:,-1,:]\n",
        "        else:\n",
        "            # use mean\n",
        "            last_tensor = torch.mean(lstm_out[:,:], dim=1)\n",
        "    \n",
        "        out = self.linear(last_tensor)\n",
        "        # print(out.shape)\n",
        "        return torch.sigmoid(out)"
      ],
      "metadata": {
        "id": "F9pVLyVrpfib"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем кастомный класс Датасета"
      ],
      "metadata": {
        "id": "_PRwnYwhzCGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class DataWrapper(Dataset):\n",
        "    def __init__(self, data, target, transform=None):\n",
        "        self.data = torch.from_numpy(data).long()\n",
        "        self.target = torch.from_numpy(target).long()\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        \n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "            \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "lX3mllpXsra3"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем из наших данных кастомные датасеты и создаем лоадеры"
      ],
      "metadata": {
        "id": "fzCkhKrazGNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_dataset = DataWrapper(x_train, df_train['label'].values)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = DataWrapper(x_val, df_val['label'].values)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "Q2-XGK6Istyh"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем модель"
      ],
      "metadata": {
        "id": "W8Tl5pPszPiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMFixedLen(vocab_size=max_words)\n",
        "device = 'cpu'"
      ],
      "metadata": {
        "id": "us8tbR2ktLv_"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in model.parameters()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96cwz4NgtOu_",
        "outputId": "063308c5-50b8-4d70-bec3-ba4c6bb03dbe"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMFixedLen(\n",
            "  (embeddings): Embedding(2500, 128, padding_idx=0)\n",
            "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True)\n",
            "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "Parameters: 584321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция ошибки и оптимизатор"
      ],
      "metadata": {
        "id": "td14WwznzTCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "0XATTxnxtOxK"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Т.к. имеется сильный дисбаланс классов, для логирования я использую F-меру для минорного класса (которого значительно меньше)"
      ],
      "metadata": {
        "id": "BUog1lEm39Bd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запускаем обучение"
      ],
      "metadata": {
        "id": "DCiBl_kxzXdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ssl import PROTOCOL_TLS_CLIENT\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "th = 0.5\n",
        "epochs = 5\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    tp, fp, fn = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        tp += ((labels==1) & (pred_labels == 1)).sum()\n",
        "        fp += ((labels==0) & (pred_labels == 1)).sum()\n",
        "        fn += ((labels==1) & (pred_labels == 0)).sum()\n",
        "        precision = tp / (tp + fp)\n",
        "        recall = tp / (tp + fn)\n",
        "        f_measure = 2*(precision*recall)/ (precision + recall)\n",
        "        #tp_running_items += len([l for l in labels if l==1])       \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 150 == 0:    # печатаем каждые 150 batches\n",
        "            model.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {loss:.3f}. ' \\\n",
        "                  #f'Precision: {precision:.3f}. ' \\\n",
        "                  #f'Recall: {recall:.3f}. ' \\\n",
        "                  f'F-measure: {f_measure:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "            train_loss_history.append(loss)\n",
        "\n",
        "            # выводим статистику на тестовых данных\n",
        "            test_tp, test_fp, test_fn = 0.0, 0.0, 0.0\n",
        "            for j, data in enumerate(val_loader):\n",
        "                test_labels = data[1].to(device)\n",
        "                test_outputs = model(data[0].to(device))\n",
        "                \n",
        "                # подсчет ошибки на тесте\n",
        "                test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "                # подсчет метрики на тесте\n",
        "\n",
        "                pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "                test_tp += ((test_labels==1) & (pred_test_labels == 1)).sum()\n",
        "                test_fp += ((test_labels==0) & (pred_test_labels == 1)).sum()\n",
        "                test_fn += ((test_labels==1) & (pred_test_labels == 0)).sum()\n",
        "                test_precision = test_tp / (test_tp + test_fp)\n",
        "                test_recall = test_tp / (test_tp + test_fn)\n",
        "                test_f_measure = 2*(test_precision*test_recall)/ (test_precision + test_recall)\n",
        "\n",
        "            test_loss_history.append(test_loss.item())\n",
        "            print(f'Test loss: {test_loss:.3f}.' \\\n",
        "                  #f'Test Precision: {test_recall:.3f}. ' \\\n",
        "                  #f'Test Recall: {test_recall:.3f}. ' \\\n",
        "                  f'Test F-measure: {test_f_measure:.3f}', end='. ')\n",
        "            print('\\n')\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu-NINW8tOzX",
        "outputId": "ba1de452-ce2b-4f89-9bde-863a5e4fbfda"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/213]. Loss: 0.721. F-measure: 0.184. Test loss: 0.644.Test F-measure: nan. \n",
            "\n",
            "Epoch [1/5]. Step [151/213]. Loss: 0.196. F-measure: 0.017. Test loss: 0.074.Test F-measure: nan. \n",
            "\n",
            "Epoch [2/5]. Step [1/213]. Loss: 0.295. F-measure: nan. Test loss: 0.068.Test F-measure: nan. \n",
            "\n",
            "Epoch [2/5]. Step [151/213]. Loss: 0.302. F-measure: nan. Test loss: 0.040.Test F-measure: nan. \n",
            "\n",
            "Epoch [3/5]. Step [1/213]. Loss: 0.243. F-measure: nan. Test loss: 0.084.Test F-measure: nan. \n",
            "\n",
            "Epoch [3/5]. Step [151/213]. Loss: 0.187. F-measure: nan. Test loss: 0.047.Test F-measure: nan. \n",
            "\n",
            "Epoch [4/5]. Step [1/213]. Loss: 0.242. F-measure: nan. Test loss: 0.054.Test F-measure: nan. \n",
            "\n",
            "Epoch [4/5]. Step [151/213]. Loss: 0.063. F-measure: 0.201. Test loss: 0.996.Test F-measure: 0.012. \n",
            "\n",
            "Epoch [5/5]. Step [1/213]. Loss: 0.183. F-measure: 0.609. Test loss: 0.096.Test F-measure: 0.507. \n",
            "\n",
            "Epoch [5/5]. Step [151/213]. Loss: 0.143. F-measure: 0.604. Test loss: 0.114.Test F-measure: 0.522. \n",
            "\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_2_layers_test_f_measure = test_f_measure\n",
        "lstm_2_layers_train_f_measure = f_measure\n",
        "lstm_2_layers_test_f_measure, lstm_2_layers_train_f_measure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVpz6YonXizI",
        "outputId": "6259581e-48b5-49d4-f5a9-029fbe839c89"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5216), tensor(0.5975))"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначала модель все предсказывала нулем, но к 4-й эпохе f-мера по 1 классу (которого гораздо меньше), наконец, начала расти. Итоговый результат не самый лучший, вероятно еще стоит обучить 5 эпох\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tToHRg1LzaaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "model.train()\n",
        "th = 0.5\n",
        "epochs = 5\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    tp, fp, fn = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        tp += ((labels==1) & (pred_labels == 1)).sum()\n",
        "        fp += ((labels==0) & (pred_labels == 1)).sum()\n",
        "        fn += ((labels==1) & (pred_labels == 0)).sum()\n",
        "        precision = tp / (tp + fp)\n",
        "        recall = tp / (tp + fn)\n",
        "        f_measure = 2*(precision*recall)/ (precision + recall)\n",
        "        #tp_running_items += len([l for l in labels if l==1])       \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 150 == 0:    # печатаем каждые 150 batches\n",
        "            model.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {loss:.3f}. ' \\\n",
        "                  #f'Precision: {precision:.3f}. ' \\\n",
        "                  #f'Recall: {recall:.3f}. ' \\\n",
        "                  f'F-measure: {f_measure:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "            train_loss_history.append(loss)\n",
        "\n",
        "            # выводим статистику на тестовых данных\n",
        "            test_tp, test_fp, test_fn = 0.0, 0.0, 0.0\n",
        "            for j, data in enumerate(val_loader):\n",
        "                test_labels = data[1].to(device)\n",
        "                test_outputs = model(data[0].to(device))\n",
        "                \n",
        "                # подсчет ошибки на тесте\n",
        "                test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "                # подсчет метрики на тесте\n",
        "\n",
        "                pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "                test_tp += ((test_labels==1) & (pred_test_labels == 1)).sum()\n",
        "                test_fp += ((test_labels==0) & (pred_test_labels == 1)).sum()\n",
        "                test_fn += ((test_labels==1) & (pred_test_labels == 0)).sum()\n",
        "                test_precision = test_tp / (test_tp + test_fp)\n",
        "                test_recall = test_tp / (test_tp + test_fn)\n",
        "                test_f_measure = 2*(test_precision*test_recall)/ (test_precision + test_recall)\n",
        "\n",
        "            test_loss_history.append(test_loss.item())\n",
        "            print(f'Test loss: {test_loss:.3f}.' \\\n",
        "                  #f'Test Precision: {test_recall:.3f}. ' \\\n",
        "                  #f'Test Recall: {test_recall:.3f}. ' \\\n",
        "                  f'Test F-measure: {test_f_measure:.3f}', end='. ')\n",
        "            print('\\n')\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7ii1D7GmyQx",
        "outputId": "53bcac52-f2dd-41fd-ee2e-0ad3a9c48a7e"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/213]. Loss: 0.107. F-measure: 0.667. Test loss: 0.008.Test F-measure: 0.457. \n",
            "\n",
            "Epoch [1/5]. Step [151/213]. Loss: 0.114. F-measure: 0.648. Test loss: 0.005.Test F-measure: 0.410. \n",
            "\n",
            "Epoch [2/5]. Step [1/213]. Loss: 0.069. F-measure: 0.800. Test loss: 0.154.Test F-measure: 0.593. \n",
            "\n",
            "Epoch [2/5]. Step [151/213]. Loss: 0.192. F-measure: 0.701. Test loss: 1.980.Test F-measure: 0.566. \n",
            "\n",
            "Epoch [3/5]. Step [1/213]. Loss: 0.133. F-measure: 0.828. Test loss: 0.005.Test F-measure: 0.588. \n",
            "\n",
            "Epoch [3/5]. Step [151/213]. Loss: 0.107. F-measure: 0.693. Test loss: 0.032.Test F-measure: 0.569. \n",
            "\n",
            "Epoch [4/5]. Step [1/213]. Loss: 0.197. F-measure: 0.714. Test loss: 0.190.Test F-measure: 0.590. \n",
            "\n",
            "Epoch [4/5]. Step [151/213]. Loss: 0.060. F-measure: 0.711. Test loss: 0.027.Test F-measure: 0.540. \n",
            "\n",
            "Epoch [5/5]. Step [1/213]. Loss: 0.069. F-measure: 0.917. Test loss: 0.005.Test F-measure: 0.587. \n",
            "\n",
            "Epoch [5/5]. Step [151/213]. Loss: 0.094. F-measure: 0.738. Test loss: 0.007.Test F-measure: 0.558. \n",
            "\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_2_layers_test_f_measure_10ep = test_f_measure\n",
        "lstm_2_layers_train_f_measure_10ep = f_measure\n",
        "lstm_2_layers_test_f_measure_10ep, lstm_2_layers_train_f_measure_10ep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sf_YiiC-nk4K",
        "outputId": "c5baf338-fac5-4b67-829c-998d7e0a15d9"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5582), tensor(0.7362))"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "после дополнительных 5-ти эпох метрика увеличилась, но очень уж большое переобучение"
      ],
      "metadata": {
        "id": "uwzuvJcTnYcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Попробуем LSTM из 1-го слоя"
      ],
      "metadata": {
        "id": "asIrK4gkXB8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMFixedLen(nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, use_last=True):\n",
        "        super().__init__()\n",
        "        self.use_last = use_last\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, ht = self.lstm(x)\n",
        "       \n",
        "        if self.use_last:\n",
        "            last_tensor = lstm_out[:,-1,:]\n",
        "        else:\n",
        "            # use mean\n",
        "            last_tensor = torch.mean(lstm_out[:,:], dim=1)\n",
        "    \n",
        "        out = self.linear(last_tensor)\n",
        "        # print(out.shape)\n",
        "        return torch.sigmoid(out)"
      ],
      "metadata": {
        "id": "6aQBMr_tXUeZ"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMFixedLen(vocab_size=max_words)\n",
        "device = 'cpu'"
      ],
      "metadata": {
        "id": "_LbJgkZ-YBhZ"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in model.parameters()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewQHDKRdpMeQ",
        "outputId": "f36b3aed-cd49-4b70-a1a1-1b8fe06aa410"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMFixedLen(\n",
            "  (embeddings): Embedding(2500, 128, padding_idx=0)\n",
            "  (lstm): LSTM(128, 128, batch_first=True)\n",
            "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "Parameters: 452225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "8KXMG83WpN1F"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "model.train()\n",
        "th = 0.5\n",
        "epochs = 5\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    tp, fp, fn = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        tp += ((labels==1) & (pred_labels == 1)).sum()\n",
        "        fp += ((labels==0) & (pred_labels == 1)).sum()\n",
        "        fn += ((labels==1) & (pred_labels == 0)).sum()\n",
        "        precision = tp / (tp + fp)\n",
        "        recall = tp / (tp + fn)\n",
        "        f_measure = 2*(precision*recall)/ (precision + recall)\n",
        "        #tp_running_items += len([l for l in labels if l==1])       \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 150 == 0:    # печатаем каждые 150 batches\n",
        "            model.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {loss:.3f}. ' \\\n",
        "                  #f'Precision: {precision:.3f}. ' \\\n",
        "                  #f'Recall: {recall:.3f}. ' \\\n",
        "                  f'F-measure: {f_measure:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "            train_loss_history.append(loss)\n",
        "\n",
        "            # выводим статистику на тестовых данных\n",
        "            test_tp, test_fp, test_fn = 0.0, 0.0, 0.0\n",
        "            for j, data in enumerate(val_loader):\n",
        "                test_labels = data[1].to(device)\n",
        "                test_outputs = model(data[0].to(device))\n",
        "                \n",
        "                # подсчет ошибки на тесте\n",
        "                test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "                # подсчет метрики на тесте\n",
        "\n",
        "                pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "                test_tp += ((test_labels==1) & (pred_test_labels == 1)).sum()\n",
        "                test_fp += ((test_labels==0) & (pred_test_labels == 1)).sum()\n",
        "                test_fn += ((test_labels==1) & (pred_test_labels == 0)).sum()\n",
        "                test_precision = test_tp / (test_tp + test_fp)\n",
        "                test_recall = test_tp / (test_tp + test_fn)\n",
        "                test_f_measure = 2*(test_precision*test_recall)/ (test_precision + test_recall)\n",
        "\n",
        "            test_loss_history.append(test_loss.item())\n",
        "            print(f'Test loss: {test_loss:.3f}.' \\\n",
        "                  #f'Test Precision: {test_recall:.3f}. ' \\\n",
        "                  #f'Test Recall: {test_recall:.3f}. ' \\\n",
        "                  f'Test F-measure: {test_f_measure:.3f}', end='. ')\n",
        "            print('\\n')\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RbE8QhAX9qV",
        "outputId": "7ee51ec5-2e15-4817-ab3b-68756bae73ca"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/213]. Loss: 0.730. F-measure: 0.158. Test loss: 0.624.Test F-measure: nan. \n",
            "\n",
            "Epoch [1/5]. Step [151/213]. Loss: 0.260. F-measure: 0.016. Test loss: 0.945.Test F-measure: nan. \n",
            "\n",
            "Epoch [2/5]. Step [1/213]. Loss: 0.273. F-measure: nan. Test loss: 0.857.Test F-measure: nan. \n",
            "\n",
            "Epoch [2/5]. Step [151/213]. Loss: 0.320. F-measure: nan. Test loss: 0.064.Test F-measure: nan. \n",
            "\n",
            "Epoch [3/5]. Step [1/213]. Loss: 0.259. F-measure: nan. Test loss: 0.078.Test F-measure: nan. \n",
            "\n",
            "Epoch [3/5]. Step [151/213]. Loss: 0.273. F-measure: nan. Test loss: 0.050.Test F-measure: nan. \n",
            "\n",
            "Epoch [4/5]. Step [1/213]. Loss: 0.225. F-measure: nan. Test loss: 0.078.Test F-measure: nan. \n",
            "\n",
            "Epoch [4/5]. Step [151/213]. Loss: 0.164. F-measure: nan. Test loss: 0.676.Test F-measure: nan. \n",
            "\n",
            "Epoch [5/5]. Step [1/213]. Loss: 0.314. F-measure: 0.143. Test loss: 0.044.Test F-measure: 0.383. \n",
            "\n",
            "Epoch [5/5]. Step [151/213]. Loss: 0.221. F-measure: 0.478. Test loss: 0.008.Test F-measure: 0.467. \n",
            "\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_1_layer_test_f_measure = test_f_measure\n",
        "lstm_1_layer_train_f_measure = f_measure\n",
        "lstm_1_layer_test_f_measure, lstm_1_layer_train_f_measure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h1fftFAoNW0",
        "outputId": "ac2319de-5e62-4753-dddf-cd113c54ace5"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4665), tensor(0.4873))"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Однослойная показала результат хуже 2-слойной"
      ],
      "metadata": {
        "id": "K1UxMHotoHVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем 3 слоя"
      ],
      "metadata": {
        "id": "Ys2Vuti1oMXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMFixedLen(nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim=256, hidden_dim=128, use_last=True):\n",
        "        super().__init__()\n",
        "        self.use_last = use_last\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=3, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, ht = self.lstm(x)\n",
        "       \n",
        "        if self.use_last:\n",
        "            last_tensor = lstm_out[:,-1,:]\n",
        "        else:\n",
        "            # use mean\n",
        "            last_tensor = torch.mean(lstm_out[:,:], dim=1)\n",
        "    \n",
        "        out = self.linear(last_tensor)\n",
        "        # print(out.shape)\n",
        "        return torch.sigmoid(out)"
      ],
      "metadata": {
        "id": "H28-FZo_oeFG"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMFixedLen(vocab_size=max_words)\n",
        "device = 'cpu'"
      ],
      "metadata": {
        "id": "g0oBnxo8oeHY"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in model.parameters()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z39ppArWp2C5",
        "outputId": "9ce6566d-a528-4e49-c0dd-f15e7d1d73cf"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMFixedLen(\n",
            "  (embeddings): Embedding(2500, 256, padding_idx=0)\n",
            "  (lstm): LSTM(256, 128, num_layers=3, batch_first=True)\n",
            "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "Parameters: 1101953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "xLOmQ6IVp5-H"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "model.train()\n",
        "th = 0.5\n",
        "epochs = 5\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    tp, fp, fn = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        tp += ((labels==1) & (pred_labels == 1)).sum()\n",
        "        fp += ((labels==0) & (pred_labels == 1)).sum()\n",
        "        fn += ((labels==1) & (pred_labels == 0)).sum()\n",
        "        precision = tp / (tp + fp)\n",
        "        recall = tp / (tp + fn)\n",
        "        f_measure = 2*(precision*recall)/ (precision + recall)\n",
        "        #tp_running_items += len([l for l in labels if l==1])       \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 150 == 0:    # печатаем каждые 150 batches\n",
        "            model.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {loss:.3f}. ' \\\n",
        "                  #f'Precision: {precision:.3f}. ' \\\n",
        "                  #f'Recall: {recall:.3f}. ' \\\n",
        "                  f'F-measure: {f_measure:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "            train_loss_history.append(loss)\n",
        "\n",
        "            # выводим статистику на тестовых данных\n",
        "            test_tp, test_fp, test_fn = 0.0, 0.0, 0.0\n",
        "            for j, data in enumerate(val_loader):\n",
        "                test_labels = data[1].to(device)\n",
        "                test_outputs = model(data[0].to(device))\n",
        "                \n",
        "                # подсчет ошибки на тесте\n",
        "                test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "                # подсчет метрики на тесте\n",
        "\n",
        "                pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "                test_tp += ((test_labels==1) & (pred_test_labels == 1)).sum()\n",
        "                test_fp += ((test_labels==0) & (pred_test_labels == 1)).sum()\n",
        "                test_fn += ((test_labels==1) & (pred_test_labels == 0)).sum()\n",
        "                test_precision = test_tp / (test_tp + test_fp)\n",
        "                test_recall = test_tp / (test_tp + test_fn)\n",
        "                test_f_measure = 2*(test_precision*test_recall)/ (test_precision + test_recall)\n",
        "\n",
        "            test_loss_history.append(test_loss.item())\n",
        "            print(f'Test loss: {test_loss:.3f}.' \\\n",
        "                  #f'Test Precision: {test_recall:.3f}. ' \\\n",
        "                  #f'Test Recall: {test_recall:.3f}. ' \\\n",
        "                  f'Test F-measure: {test_f_measure:.3f}', end='. ')\n",
        "            print('\\n')\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lrb4yttAoeJu",
        "outputId": "4d3a1933-9322-408d-9be1-e59e56aa3d02"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/213]. Loss: 0.718. F-measure: 0.118. Test loss: 0.485.Test F-measure: nan. \n",
            "\n",
            "Epoch [1/5]. Step [151/213]. Loss: 0.239. F-measure: 0.011. Test loss: 0.054.Test F-measure: nan. \n",
            "\n",
            "Epoch [2/5]. Step [1/213]. Loss: 0.315. F-measure: nan. Test loss: 0.083.Test F-measure: nan. \n",
            "\n",
            "Epoch [2/5]. Step [151/213]. Loss: 0.220. F-measure: nan. Test loss: 0.077.Test F-measure: nan. \n",
            "\n",
            "Epoch [3/5]. Step [1/213]. Loss: 0.273. F-measure: nan. Test loss: 0.046.Test F-measure: nan. \n",
            "\n",
            "Epoch [3/5]. Step [151/213]. Loss: 0.244. F-measure: nan. Test loss: 0.036.Test F-measure: nan. \n",
            "\n",
            "Epoch [4/5]. Step [1/213]. Loss: 0.291. F-measure: nan. Test loss: 0.148.Test F-measure: nan. \n",
            "\n",
            "Epoch [4/5]. Step [151/213]. Loss: 0.124. F-measure: nan. Test loss: 0.099.Test F-measure: nan. \n",
            "\n",
            "Epoch [5/5]. Step [1/213]. Loss: 0.181. F-measure: nan. Test loss: 0.094.Test F-measure: nan. \n",
            "\n",
            "Epoch [5/5]. Step [151/213]. Loss: 0.080. F-measure: 0.363. Test loss: 0.443.Test F-measure: 0.357. \n",
            "\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_3_layers_test_f_measure = test_f_measure\n",
        "lstm_3_layers_train_f_measure = f_measure\n",
        "lstm_3_layers_test_f_measure, lstm_3_layers_train_f_measure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxz6iORmoeME",
        "outputId": "9baeb409-a74b-4b5b-e214-2744923ac350"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3571), tensor(0.3885))"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Слабый результат на 5-ти эпохах и очень долгое обучение"
      ],
      "metadata": {
        "id": "sBOKB_Tkr0Ki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вернем 1 слой и увеличим размер эмбединга и скрытого расстояния"
      ],
      "metadata": {
        "id": "_KDrf9cCr72r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMFixedLen(nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim=256, hidden_dim=256, use_last=True):\n",
        "        super().__init__()\n",
        "        self.use_last = use_last\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, ht = self.lstm(x)\n",
        "       \n",
        "        if self.use_last:\n",
        "            last_tensor = lstm_out[:,-1,:]\n",
        "        else:\n",
        "            # use mean\n",
        "            last_tensor = torch.mean(lstm_out[:,:], dim=1)\n",
        "    \n",
        "        out = self.linear(last_tensor)\n",
        "        # print(out.shape)\n",
        "        return torch.sigmoid(out)"
      ],
      "metadata": {
        "id": "E5loZUcXoeOn"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMFixedLen(vocab_size=max_words)\n",
        "device = 'cpu'"
      ],
      "metadata": {
        "id": "O55g0PTasePY"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in model.parameters()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhhZD_ZDsOd9",
        "outputId": "24e2004a-b272-4c15-f851-6c0a1e2cbdfe"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMFixedLen(\n",
            "  (embeddings): Embedding(2500, 256, padding_idx=0)\n",
            "  (lstm): LSTM(256, 256, batch_first=True)\n",
            "  (linear): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "Parameters: 1166593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "ga8JhoV0sOgK"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "model.train()\n",
        "th = 0.5\n",
        "epochs = 5\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    tp, fp, fn = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        tp += ((labels==1) & (pred_labels == 1)).sum()\n",
        "        fp += ((labels==0) & (pred_labels == 1)).sum()\n",
        "        fn += ((labels==1) & (pred_labels == 0)).sum()\n",
        "        precision = tp / (tp + fp)\n",
        "        recall = tp / (tp + fn)\n",
        "        f_measure = 2*(precision*recall)/ (precision + recall)\n",
        "        #tp_running_items += len([l for l in labels if l==1])       \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 150 == 0:    # печатаем каждые 150 batches\n",
        "            model.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {loss:.3f}. ' \\\n",
        "                  #f'Precision: {precision:.3f}. ' \\\n",
        "                  #f'Recall: {recall:.3f}. ' \\\n",
        "                  f'F-measure: {f_measure:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "            train_loss_history.append(loss)\n",
        "\n",
        "            # выводим статистику на тестовых данных\n",
        "            test_tp, test_fp, test_fn = 0.0, 0.0, 0.0\n",
        "            for j, data in enumerate(val_loader):\n",
        "                test_labels = data[1].to(device)\n",
        "                test_outputs = model(data[0].to(device))\n",
        "                \n",
        "                # подсчет ошибки на тесте\n",
        "                test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "                # подсчет метрики на тесте\n",
        "\n",
        "                pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "                test_tp += ((test_labels==1) & (pred_test_labels == 1)).sum()\n",
        "                test_fp += ((test_labels==0) & (pred_test_labels == 1)).sum()\n",
        "                test_fn += ((test_labels==1) & (pred_test_labels == 0)).sum()\n",
        "                test_precision = test_tp / (test_tp + test_fp)\n",
        "                test_recall = test_tp / (test_tp + test_fn)\n",
        "                test_f_measure = 2*(test_precision*test_recall)/ (test_precision + test_recall)\n",
        "\n",
        "            test_loss_history.append(test_loss.item())\n",
        "            print(f'Test loss: {test_loss:.3f}.' \\\n",
        "                  #f'Test Precision: {test_recall:.3f}. ' \\\n",
        "                  #f'Test Recall: {test_recall:.3f}. ' \\\n",
        "                  f'Test F-measure: {test_f_measure:.3f}', end='. ')\n",
        "            print('\\n')\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBKGncfjsOiq",
        "outputId": "8479d113-8abb-469b-d5cc-ccaba2055d60"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/213]. Loss: 0.704. F-measure: 0.061. Test loss: 0.478.Test F-measure: nan. \n",
            "\n",
            "Epoch [1/5]. Step [151/213]. Loss: 0.237. F-measure: 0.005. Test loss: 0.053.Test F-measure: nan. \n",
            "\n",
            "Epoch [2/5]. Step [1/213]. Loss: 0.173. F-measure: nan. Test loss: 0.063.Test F-measure: nan. \n",
            "\n",
            "Epoch [2/5]. Step [151/213]. Loss: 0.356. F-measure: nan. Test loss: 0.074.Test F-measure: nan. \n",
            "\n",
            "Epoch [3/5]. Step [1/213]. Loss: 0.212. F-measure: 0.154. Test loss: 0.042.Test F-measure: 0.269. \n",
            "\n",
            "Epoch [3/5]. Step [151/213]. Loss: 0.185. F-measure: 0.352. Test loss: 0.007.Test F-measure: 0.371. \n",
            "\n",
            "Epoch [4/5]. Step [1/213]. Loss: 0.175. F-measure: 0.353. Test loss: 0.041.Test F-measure: 0.460. \n",
            "\n",
            "Epoch [4/5]. Step [151/213]. Loss: 0.101. F-measure: 0.568. Test loss: 0.039.Test F-measure: 0.408. \n",
            "\n",
            "Epoch [5/5]. Step [1/213]. Loss: 0.209. F-measure: 0.560. Test loss: 0.084.Test F-measure: 0.477. \n",
            "\n",
            "Epoch [5/5]. Step [151/213]. Loss: 0.128. F-measure: 0.637. Test loss: 0.009.Test F-measure: 0.478. \n",
            "\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_1_layer_test_f_measure_256_emb = test_f_measure\n",
        "lstm_1_layer_train_f_measure_256_emb = f_measure\n",
        "lstm_1_layer_test_f_measure_256_emb, lstm_1_layer_train_f_measure_256_emb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN45EKzQu7rH",
        "outputId": "cbb3295e-89a9-4531-a6e2-bf89b7172005"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4777), tensor(0.6437))"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Увеличение размерности эмбединга и скрытых состояний дало положительный прирост к метрике, но также есть большое переобучение"
      ],
      "metadata": {
        "id": "BUFtDK2rvOSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наконец, попробуем обычную 2-слойную LSTM, но будем снимать не послдений скрытый слой, а будем усреднять"
      ],
      "metadata": {
        "id": "lBZ6JzwovaV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMFixedLen(nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, use_last=False):\n",
        "        super().__init__()\n",
        "        self.use_last = use_last\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, ht = self.lstm(x)\n",
        "       \n",
        "        if self.use_last:\n",
        "            last_tensor = lstm_out[:,-1,:]\n",
        "        else:\n",
        "            # use mean\n",
        "            last_tensor = torch.mean(lstm_out[:,:], dim=1)\n",
        "    \n",
        "        out = self.linear(last_tensor)\n",
        "        # print(out.shape)\n",
        "        return torch.sigmoid(out)"
      ],
      "metadata": {
        "id": "wL7qCu7NsOk8"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMFixedLen(vocab_size=max_words)\n",
        "device = 'cpu'"
      ],
      "metadata": {
        "id": "hjscvbEtsOnO"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in model.parameters()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82IRXqLvsOpM",
        "outputId": "542803de-09d6-417c-af08-da4e4d8806ad"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMFixedLen(\n",
            "  (embeddings): Embedding(2500, 128, padding_idx=0)\n",
            "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True)\n",
            "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "Parameters: 584321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "XpJ8-gLXv-h-"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "model.train()\n",
        "th = 0.5\n",
        "epochs = 5\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    tp, fp, fn = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        tp += ((labels==1) & (pred_labels == 1)).sum()\n",
        "        fp += ((labels==0) & (pred_labels == 1)).sum()\n",
        "        fn += ((labels==1) & (pred_labels == 0)).sum()\n",
        "        precision = tp / (tp + fp)\n",
        "        recall = tp / (tp + fn)\n",
        "        f_measure = 2*(precision*recall)/ (precision + recall)\n",
        "        #tp_running_items += len([l for l in labels if l==1])       \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 150 == 0:    # печатаем каждые 150 batches\n",
        "            model.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {loss:.3f}. ' \\\n",
        "                  #f'Precision: {precision:.3f}. ' \\\n",
        "                  #f'Recall: {recall:.3f}. ' \\\n",
        "                  f'F-measure: {f_measure:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "            train_loss_history.append(loss)\n",
        "\n",
        "            # выводим статистику на тестовых данных\n",
        "            test_tp, test_fp, test_fn = 0.0, 0.0, 0.0\n",
        "            for j, data in enumerate(val_loader):\n",
        "                test_labels = data[1].to(device)\n",
        "                test_outputs = model(data[0].to(device))\n",
        "                \n",
        "                # подсчет ошибки на тесте\n",
        "                test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "                # подсчет метрики на тесте\n",
        "\n",
        "                pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "                test_tp += ((test_labels==1) & (pred_test_labels == 1)).sum()\n",
        "                test_fp += ((test_labels==0) & (pred_test_labels == 1)).sum()\n",
        "                test_fn += ((test_labels==1) & (pred_test_labels == 0)).sum()\n",
        "                test_precision = test_tp / (test_tp + test_fp)\n",
        "                test_recall = test_tp / (test_tp + test_fn)\n",
        "                test_f_measure = 2*(test_precision*test_recall)/ (test_precision + test_recall)\n",
        "\n",
        "            test_loss_history.append(test_loss.item())\n",
        "            print(f'Test loss: {test_loss:.3f}.' \\\n",
        "                  #f'Test Precision: {test_recall:.3f}. ' \\\n",
        "                  #f'Test Recall: {test_recall:.3f}. ' \\\n",
        "                  f'Test F-measure: {test_f_measure:.3f}', end='. ')\n",
        "            print('\\n')\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmE02C3-v-kD",
        "outputId": "88ca7ec2-f0da-4eab-a736-e60230a7e590"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/213]. Loss: 0.702. F-measure: 0.031. Test loss: 0.521.Test F-measure: nan. \n",
            "\n",
            "Epoch [1/5]. Step [151/213]. Loss: 0.173. F-measure: 0.315. Test loss: 0.019.Test F-measure: 0.507. \n",
            "\n",
            "Epoch [2/5]. Step [1/213]. Loss: 0.085. F-measure: 0.857. Test loss: 0.068.Test F-measure: 0.547. \n",
            "\n",
            "Epoch [2/5]. Step [151/213]. Loss: 0.149. F-measure: 0.644. Test loss: 0.037.Test F-measure: 0.584. \n",
            "\n",
            "Epoch [3/5]. Step [1/213]. Loss: 0.052. F-measure: 0.833. Test loss: 0.008.Test F-measure: 0.599. \n",
            "\n",
            "Epoch [3/5]. Step [151/213]. Loss: 0.067. F-measure: 0.723. Test loss: 0.013.Test F-measure: 0.609. \n",
            "\n",
            "Epoch [4/5]. Step [1/213]. Loss: 0.063. F-measure: 0.750. Test loss: 0.007.Test F-measure: 0.631. \n",
            "\n",
            "Epoch [4/5]. Step [151/213]. Loss: 0.083. F-measure: 0.768. Test loss: 0.034.Test F-measure: 0.611. \n",
            "\n",
            "Epoch [5/5]. Step [1/213]. Loss: 0.078. F-measure: 0.750. Test loss: 0.026.Test F-measure: 0.621. \n",
            "\n",
            "Epoch [5/5]. Step [151/213]. Loss: 0.072. F-measure: 0.807. Test loss: 0.780.Test F-measure: 0.611. \n",
            "\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_2_layers_test_f_measure_mean_last_tensor = test_f_measure\n",
        "lstm_2_layers_train_f_measure_mean_last_tensor = f_measure\n",
        "lstm_2_layers_test_f_measure_mean_last_tensor, lstm_2_layers_train_f_measure_mean_last_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkMc9_5Av-mU",
        "outputId": "f5a6eacf-c756-4650-b102-25cf41d3e9a3"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.6106), tensor(0.7991))"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данная архитектура показала лучший результат, но есть переобучение"
      ],
      "metadata": {
        "id": "EBdGBqlYw122"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Попробуем GRU"
      ],
      "metadata": {
        "id": "YRjwghh_w7WT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 слоя, снимаем состояние с последнего скрытого состояния"
      ],
      "metadata": {
        "id": "JJL2Z-5wxTl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUFixedLen(nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, use_last=True):\n",
        "        super().__init__()\n",
        "        self.use_last = use_last\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        gru_out, ht = self.gru(x)\n",
        "       \n",
        "        if self.use_last:\n",
        "            last_tensor = gru_out[:,-1,:]\n",
        "        else:\n",
        "            # use mean\n",
        "            last_tensor = torch.mean(gru_out[:,:], dim=1)\n",
        "    \n",
        "        out = self.linear(last_tensor)\n",
        "        return torch.sigmoid(out)"
      ],
      "metadata": {
        "id": "GWG9pahwoeTA"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMFixedLen(vocab_size=max_words)\n",
        "device = 'cpu'"
      ],
      "metadata": {
        "id": "qXNEcXHxoeVI"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in model.parameters()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSOvt-gQX9vO",
        "outputId": "ab4e1c58-271e-4048-e3b6-1ffeda284f35"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMFixedLen(\n",
            "  (embeddings): Embedding(2500, 128, padding_idx=0)\n",
            "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True)\n",
            "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "Parameters: 584321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "JznzEGF5X9xl"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "model.train()\n",
        "th = 0.5\n",
        "epochs = 5\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    tp, fp, fn = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        tp += ((labels==1) & (pred_labels == 1)).sum()\n",
        "        fp += ((labels==0) & (pred_labels == 1)).sum()\n",
        "        fn += ((labels==1) & (pred_labels == 0)).sum()\n",
        "        precision = tp / (tp + fp)\n",
        "        recall = tp / (tp + fn)\n",
        "        f_measure = 2*(precision*recall)/ (precision + recall)\n",
        "        #tp_running_items += len([l for l in labels if l==1])       \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 150 == 0:    # печатаем каждые 150 batches\n",
        "            model.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {loss:.3f}. ' \\\n",
        "                  #f'Precision: {precision:.3f}. ' \\\n",
        "                  #f'Recall: {recall:.3f}. ' \\\n",
        "                  f'F-measure: {f_measure:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "            train_loss_history.append(loss)\n",
        "\n",
        "            # выводим статистику на тестовых данных\n",
        "            test_tp, test_fp, test_fn = 0.0, 0.0, 0.0\n",
        "            for j, data in enumerate(val_loader):\n",
        "                test_labels = data[1].to(device)\n",
        "                test_outputs = model(data[0].to(device))\n",
        "                \n",
        "                # подсчет ошибки на тесте\n",
        "                test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "                # подсчет метрики на тесте\n",
        "\n",
        "                pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "                test_tp += ((test_labels==1) & (pred_test_labels == 1)).sum()\n",
        "                test_fp += ((test_labels==0) & (pred_test_labels == 1)).sum()\n",
        "                test_fn += ((test_labels==1) & (pred_test_labels == 0)).sum()\n",
        "                test_precision = test_tp / (test_tp + test_fp)\n",
        "                test_recall = test_tp / (test_tp + test_fn)\n",
        "                test_f_measure = 2*(test_precision*test_recall)/ (test_precision + test_recall)\n",
        "\n",
        "            test_loss_history.append(test_loss.item())\n",
        "            print(f'Test loss: {test_loss:.3f}.' \\\n",
        "                  #f'Test Precision: {test_recall:.3f}. ' \\\n",
        "                  #f'Test Recall: {test_recall:.3f}. ' \\\n",
        "                  f'Test F-measure: {test_f_measure:.3f}', end='. ')\n",
        "            print('\\n')\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yMfD_VNxPFA",
        "outputId": "046f1e6d-4986-4027-878a-768bad475ef9"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/213]. Loss: 0.673. F-measure: nan. Test loss: 0.477.Test F-measure: nan. \n",
            "\n",
            "Epoch [1/5]. Step [151/213]. Loss: 0.202. F-measure: 0.085. Test loss: 0.044.Test F-measure: 0.187. \n",
            "\n",
            "Epoch [2/5]. Step [1/213]. Loss: 0.162. F-measure: 0.471. Test loss: 0.041.Test F-measure: 0.491. \n",
            "\n",
            "Epoch [2/5]. Step [151/213]. Loss: 0.125. F-measure: 0.582. Test loss: 0.103.Test F-measure: 0.528. \n",
            "\n",
            "Epoch [3/5]. Step [1/213]. Loss: 0.128. F-measure: 0.706. Test loss: 0.006.Test F-measure: 0.591. \n",
            "\n",
            "Epoch [3/5]. Step [151/213]. Loss: 0.140. F-measure: 0.696. Test loss: 0.002.Test F-measure: 0.617. \n",
            "\n",
            "Epoch [4/5]. Step [1/213]. Loss: 0.093. F-measure: 0.667. Test loss: 0.249.Test F-measure: 0.606. \n",
            "\n",
            "Epoch [4/5]. Step [151/213]. Loss: 0.113. F-measure: 0.763. Test loss: 0.015.Test F-measure: 0.601. \n",
            "\n",
            "Epoch [5/5]. Step [1/213]. Loss: 0.063. F-measure: 0.824. Test loss: 0.019.Test F-measure: 0.591. \n",
            "\n",
            "Epoch [5/5]. Step [151/213]. Loss: 0.101. F-measure: 0.791. Test loss: 0.004.Test F-measure: 0.600. \n",
            "\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_2_layers_test_f_measure = test_f_measure\n",
        "gru_2_layers_train_f_measure = f_measure\n",
        "gru_2_layers_test_f_measure, gru_2_layers_train_f_measure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYkoXva1xPHx",
        "outputId": "d14aa808-e5d8-4788-a4e0-577503bf5237"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.6004), tensor(0.7820))"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Хороший результат по метрике, но снова сильное переобучение"
      ],
      "metadata": {
        "id": "vBuXdNCDyJVs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем ту же архитектуру, но будем усреднять скрытые состояния"
      ],
      "metadata": {
        "id": "SwOA15Lbx-yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUFixedLen(nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, use_last=False):\n",
        "        super().__init__()\n",
        "        self.use_last = use_last\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        gru_out, ht = self.gru(x)\n",
        "       \n",
        "        if self.use_last:\n",
        "            last_tensor = gru_out[:,-1,:]\n",
        "        else:\n",
        "            # use mean\n",
        "            last_tensor = torch.mean(gru_out[:,:], dim=1)\n",
        "    \n",
        "        out = self.linear(last_tensor)\n",
        "        return torch.sigmoid(out)"
      ],
      "metadata": {
        "id": "jLP6VMXWxPKE"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMFixedLen(vocab_size=max_words)\n",
        "device = 'cpu'"
      ],
      "metadata": {
        "id": "Lt2W4QxuxPMv"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in model.parameters()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxuI2aTBX90U",
        "outputId": "3565eeb2-4783-4400-a882-cf99c7770163"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMFixedLen(\n",
            "  (embeddings): Embedding(2500, 128, padding_idx=0)\n",
            "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True)\n",
            "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "Parameters: 584321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "1Sew7KcfX92m"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "model.train()\n",
        "th = 0.5\n",
        "epochs = 5\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    tp, fp, fn = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        tp += ((labels==1) & (pred_labels == 1)).sum()\n",
        "        fp += ((labels==0) & (pred_labels == 1)).sum()\n",
        "        fn += ((labels==1) & (pred_labels == 0)).sum()\n",
        "        precision = tp / (tp + fp)\n",
        "        recall = tp / (tp + fn)\n",
        "        f_measure = 2*(precision*recall)/ (precision + recall)\n",
        "        #tp_running_items += len([l for l in labels if l==1])       \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 150 == 0:    # печатаем каждые 150 batches\n",
        "            model.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {loss:.3f}. ' \\\n",
        "                  #f'Precision: {precision:.3f}. ' \\\n",
        "                  #f'Recall: {recall:.3f}. ' \\\n",
        "                  f'F-measure: {f_measure:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "            train_loss_history.append(loss)\n",
        "\n",
        "            # выводим статистику на тестовых данных\n",
        "            test_tp, test_fp, test_fn = 0.0, 0.0, 0.0\n",
        "            for j, data in enumerate(val_loader):\n",
        "                test_labels = data[1].to(device)\n",
        "                test_outputs = model(data[0].to(device))\n",
        "                \n",
        "                # подсчет ошибки на тесте\n",
        "                test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "                # подсчет метрики на тесте\n",
        "\n",
        "                pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "                test_tp += ((test_labels==1) & (pred_test_labels == 1)).sum()\n",
        "                test_fp += ((test_labels==0) & (pred_test_labels == 1)).sum()\n",
        "                test_fn += ((test_labels==1) & (pred_test_labels == 0)).sum()\n",
        "                test_precision = test_tp / (test_tp + test_fp)\n",
        "                test_recall = test_tp / (test_tp + test_fn)\n",
        "                test_f_measure = 2*(test_precision*test_recall)/ (test_precision + test_recall)\n",
        "\n",
        "            test_loss_history.append(test_loss.item())\n",
        "            print(f'Test loss: {test_loss:.3f}.' \\\n",
        "                  #f'Test Precision: {test_recall:.3f}. ' \\\n",
        "                  #f'Test Recall: {test_recall:.3f}. ' \\\n",
        "                  f'Test F-measure: {test_f_measure:.3f}', end='. ')\n",
        "            print('\\n')\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xX4y6f_ybHy",
        "outputId": "d750d68a-d450-4776-f42b-5d6950c54ac7"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/213]. Loss: 0.715. F-measure: 0.131. Test loss: 0.504.Test F-measure: nan. \n",
            "\n",
            "Epoch [1/5]. Step [151/213]. Loss: 0.074. F-measure: 0.294. Test loss: 0.061.Test F-measure: 0.512. \n",
            "\n",
            "Epoch [2/5]. Step [1/213]. Loss: 0.146. F-measure: 0.667. Test loss: 0.036.Test F-measure: 0.540. \n",
            "\n",
            "Epoch [2/5]. Step [151/213]. Loss: 0.149. F-measure: 0.634. Test loss: 0.536.Test F-measure: 0.625. \n",
            "\n",
            "Epoch [3/5]. Step [1/213]. Loss: 0.103. F-measure: 0.818. Test loss: 0.129.Test F-measure: 0.604. \n",
            "\n",
            "Epoch [3/5]. Step [151/213]. Loss: 0.115. F-measure: 0.717. Test loss: 0.234.Test F-measure: 0.615. \n",
            "\n",
            "Epoch [4/5]. Step [1/213]. Loss: 0.080. F-measure: 0.727. Test loss: 0.051.Test F-measure: 0.627. \n",
            "\n",
            "Epoch [4/5]. Step [151/213]. Loss: 0.089. F-measure: 0.773. Test loss: 0.024.Test F-measure: 0.584. \n",
            "\n",
            "Epoch [5/5]. Step [1/213]. Loss: 0.044. F-measure: 0.800. Test loss: 0.012.Test F-measure: 0.624. \n",
            "\n",
            "Epoch [5/5]. Step [151/213]. Loss: 0.062. F-measure: 0.797. Test loss: 0.012.Test F-measure: 0.616. \n",
            "\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_2_layers_test_f_measure_mean_last_tensor = test_f_measure\n",
        "gru_2_layers_train_f_measure_mean_last_tensor = f_measure\n",
        "gru_2_layers_test_f_measure_mean_last_tensor, gru_2_layers_train_f_measure_mean_last_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SCJlQTdybKE",
        "outputId": "0aad63f7-f362-4e8b-e88e-f3fa3a601eca"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.6162), tensor(0.7946))"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лучший результат для валидационной выборки и обучается очень быстро. Но все то же переобучение."
      ],
      "metadata": {
        "id": "GLjx1lUwzw5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сделаем таблицу с результатами на валидационной выборке"
      ],
      "metadata": {
        "id": "Av9mGx6A3qDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_result = np.array([lstm_2_layers_test_f_measure, lstm_2_layers_test_f_measure_10ep, lstm_1_layer_test_f_measure, lstm_3_layers_test_f_measure, \n",
        "                        lstm_1_layer_test_f_measure_256_emb, lstm_2_layers_test_f_measure_mean_last_tensor, \n",
        "                        gru_2_layers_test_f_measure, gru_2_layers_test_f_measure_mean_last_tensor])\n",
        "naming = ['LSTM 2 слоя - 5 эпох', 'LSTM 2 слоя - 10 эпох', 'LSTM 1 слой - 5 эпох', 'LSTM 3 слоя - 5 эпох', 'LSTM 1 слой, размерность эмб и скрытого - 256',\n",
        "         'LSTM 2 слоя - усреднение скрытых состояний', 'GRU 2 слоя - последнее скрытое состояние', 'GRU 2 слоя - усреднение скрытых состояний']"
      ],
      "metadata": {
        "id": "SRCMf82bybMc"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.Series(test_result, index = naming)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEKHWCf7ybPJ",
        "outputId": "021fadf9-e58e-4a88-8b5c-7d7b9a33fe64"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM 2 слоя - 5 эпох                             0.521561\n",
              "LSTM 2 слоя - 10 эпох                            0.558233\n",
              "LSTM 1 слой - 5 эпох                             0.466531\n",
              "LSTM 3 слоя - 5 эпох                             0.357143\n",
              "LSTM 1 слой, размерность эмб и скрытого - 256    0.477733\n",
              "LSTM 2 слоя - усреднение скрытых состояний       0.610568\n",
              "GRU 2 слоя - последнее скрытое состояние         0.600355\n",
              "GRU 2 слоя - усреднение скрытых состояний        0.616197\n",
              "dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    }
  ]
}